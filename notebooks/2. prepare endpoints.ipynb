{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf582515-0ced-4781-8f64-e5fe01a141e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from dbx_utils.logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Widgets\n",
    "# --------------------------------------------------------------------\n",
    "dbutils.widgets.text(\"endpoint_table\", \"\")        # e.g. \"cat.schema.endpoint_table\"\n",
    "dbutils.widgets.text(\"task_value_key\", \"endpoints\")  # key under which to store the list\n",
    "dbutils.widgets.text(\"max_endpoints\", \"\")         # optional: limit for testing (leave empty for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1f7ef0b-a43c-40ab-af7e-c0dbe6412195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endpoint_table = dbutils.widgets.get(\"endpoint_table\")\n",
    "task_value_key = dbutils.widgets.get(\"task_value_key\") or \"endpoints\"\n",
    "max_endpoints_raw = dbutils.widgets.get(\"max_endpoints\").strip()\n",
    "\n",
    "if not endpoint_table:\n",
    "    raise ValueError(\"Widget 'endpoint_table' is required.\")\n",
    "\n",
    "max_endpoints: int | None\n",
    "if max_endpoints_raw:\n",
    "    try:\n",
    "        max_endpoints = int(max_endpoints_raw)\n",
    "    except ValueError as exc:\n",
    "        raise ValueError(f\"Invalid 'max_endpoints': {max_endpoints_raw!r}\") from exc\n",
    "else:\n",
    "    max_endpoints = None\n",
    "\n",
    "logger.info(\"Preparing endpoint list from table: %s\", endpoint_table)\n",
    "logger.info(\"Task value key: %s\", task_value_key)\n",
    "logger.info(\"Max endpoints: %s\", max_endpoints if max_endpoints is not None else \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "113ea90d-e6ee-4e69-a3bc-6d89a6a6e87b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Read endpoint table\n",
    "# --------------------------------------------------------------------\n",
    "df = spark.read.table(endpoint_table).select(\"id\", \"endpoint\", \"params\", \"job_settings\")\n",
    "\n",
    "if max_endpoints is not None:\n",
    "    df = df.limit(max_endpoints)\n",
    "\n",
    "rows = df.collect()\n",
    "logger.info(\"Fetched %d rows from endpoint table.\", len(rows))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Build list of endpoint payloads\n",
    "# Each element will be used by a For Each loop in the job\n",
    "# --------------------------------------------------------------------\n",
    "EndpointPayload = Dict[str, Any]\n",
    "payloads: List[EndpointPayload] = []\n",
    "\n",
    "for row in rows:\n",
    "    endpoint_id = row[\"id\"]\n",
    "    endpoint = row[\"endpoint\"]\n",
    "    params = row[\"params\"] or {}\n",
    "    job_settings = row[\"job_settings\"] or {}\n",
    "\n",
    "    payload: EndpointPayload = {\n",
    "        \"id\": endpoint_id,\n",
    "        \"endpoint\": endpoint,\n",
    "        \"params\": params,\n",
    "        \"job_settings\": job_settings,\n",
    "    }\n",
    "    payloads.append(payload)\n",
    "\n",
    "logger.info(\"Built endpoint payload list with %d elements.\", len(payloads))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Store in task values for downstream For Each\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "dbutils.jobs.taskValues.set(\n",
    "    key=task_value_key,\n",
    "    value=payloads,\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    \"Stored endpoint payload list as task value with key '%s'.\",\n",
    "    task_value_key,\n",
    ")\n",
    "\n",
    "# Optional: return a small summary as notebook result\n",
    "dbutils.notebook.exit(\n",
    "    f\"Prepared {len(payloads)} endpoints into task value '{task_value_key}'\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. prepare endpoints",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
